{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Validating FreeMoCap","text":""},{"location":"balance/","title":"Balance","text":""},{"location":"balance/#overview","title":"Overview","text":"<p>Patient balance and progress in rehabilitation is often measured using comprehensive  qualitative assessments. However, these tests  tend to be subjective and may not be responsive to small changes in a patient. The ability to capture human movement data while performing these clinical assessments could provide clinicians with quantitative, standardized insight into patient movement capability. </p> <p>To validate the suitability of FreeMoCap as a clinical assessment tool, we record participants performing the NIH Standing Balance Test (SBT). We then compare center of mass (COM) derived parameters based on 3D pose estimation from FreeMoCap to 3D estimates from Qualisys, a marker-based system.</p>"},{"location":"balance/#the-nih-standing-balance-test-sbt","title":"The NIH Standing Balance Test (SBT)","text":"<p>The NIH SBT is an assessment tool designed to evaluate an individual\u2019s postural stability and balance. Participants stand feet together, and are asked to stand as still as possible for 50s under increasingly difficult conditions. These conditions include:</p> <p>1) Standing with eyes open on solid ground  2) Standing with eyes closed on solid ground  3) Standing with eyes open on a foam pad  4) Standing with eyes closed on a foam pad </p> <p>In a typical assessment, an accelerometer (usually an iPhone) is worn around the participant's waist. The accelerometer measures postural sway, which is then converted into a number of NIH scores that represent overall balance ability </p>"},{"location":"balance/#methods","title":"Methods","text":""},{"location":"balance/#task-the-nih-standing-balance-test-sbt","title":"Task: The NIH Standing Balance Test (SBT)","text":"<p>Participants were asked to complete three trials of the NIH SBT. For each condition, participants were instructed to stand as still as possible for 55 seconds, keeping their gaze fixated on a specific point, feet together and arms held at their side. Participants were recorded using three different systems, detailed below. </p>"},{"location":"balance/#tracking-patient-motion","title":"Tracking Patient Motion","text":""},{"location":"balance/#qualisys","title":"Qualisys","text":"<p>Retroreflective markers were placed on the participant, and a Qualisys marker-based system was used to capture motion capture data</p>"},{"location":"balance/#freemocap","title":"FreeMoCap","text":"<p>Six webcams were set up around the subject. Cameras were calibrated, and then used to record the patient during the SBT. </p>"},{"location":"balance/#data-analysis","title":"Data Analysis","text":""},{"location":"balance/#reconstructing-3d-data","title":"Reconstructing 3D Data","text":"<p>Synchronized videos from the webcams were fed through the FreeMoCap software to reconstruct 3D joint centers. FreeMoCap data was smoothed using a low-pass, 4th order, 6Hz Butterworth filter. Qualisys data was downsampled and time-synchronized with FreeMoCap data. Specific frames were annotated for the start and end point of each balance condition within the recording. 1600 frames were analyzed for each condition. </p>"},{"location":"balance/#center-of-mass-calculation","title":"Center of Mass Calculation","text":"<p>For both systems, segment and total body center of mass was calculated using anthropometric data. For each condition, the overall path length of the center of mass was calculated. Center of mass position was also used to calculate center of mass velocity as well during each condition. </p>"},{"location":"balance/#results","title":"Results","text":""},{"location":"balance/#center-of-mass-dispersion","title":"Center of mass dispersion","text":"<p>The 2d ground plane projection of the center of mass shows increased dispersion during progressively harder stances.</p>"},{"location":"balance/#normalized-path-length","title":"Normalized path length","text":"<p>Center of mass path length shows a generally increasing trend across stances.</p>"},{"location":"balance/#com-position-and-velocity","title":"COM Position and Velocity","text":""},{"location":"balance/#com-velocity-distribution","title":"COM Velocity Distribution","text":"<p>You can explore the distribution of center of mass velocity for each stance condition below.</p> <p> </p> <p> </p> <p> </p>"},{"location":"gait/","title":"Gait","text":""},{"location":"gait/#overview","title":"Overview","text":"<p>For this part of validation, we look at the accuracy of FreeMoCap in capturing a dynamic movement, specifically gait analysis. </p>"},{"location":"gait/#methods","title":"Methods","text":"<p>Participants were asked to walk on a treadmill, with the speed increasing in increments of .5m/s every 30 seconds - starting from 0m/s until 2.5m/s</p>"},{"location":"gait/#tracking-patient-motion","title":"Tracking Patient Motion","text":""},{"location":"gait/#qualisys","title":"Qualisys","text":"<p>Retroreflective markers were placed on the participant, and a Qualisys marker-based system was used to capture motion capture data</p>"},{"location":"gait/#freemocap","title":"FreeMoCap","text":"<p>Six webcams were set up around the subject. Cameras were calibrated, and then used to record the patient during the SBT. </p>"},{"location":"gait/#data-analysis","title":"Data Analysis","text":""},{"location":"gait/#reconstructing-3d-data","title":"Reconstructing 3D Data","text":"<p>Synchronized videos from the webcams were fed through the FreeMoCap software to reconstruct 3D joint centers. FreeMoCap data was smoothed using a low-pass, 4th order, 6Hz Butterworth filter. Qualisys data was downsampled and time-synchronized with FreeMoCap data. Specific frames were annotated for the start and end point of each balance condition within the recording. 1600 frames were analyzed for each condition. </p>"},{"location":"gait/#results","title":"Results","text":""},{"location":"gait/#comparison-of-3d-data-between-qualisys-and-mediapipe","title":"Comparison of 3D Data Between Qualisys and MediaPipe","text":"<p>Take a look at a representative trial of 3D data. You can pick specific markers to look at the X, Y and Z trajectories for - with Qualisys plotted if an equivalent marker exists. </p> <p> </p>"},{"location":"gait/#extracting-gait-events","title":"Extracting gait events","text":"<p>We can then use the methods from Zeni et. all (2008) to extract heel strike and toe off from our 3D Qualisys and FreeMoCap data. </p> <p>Here's a look at that data from 50s of walking from a representative trial for both the left and right foot. </p>"},{"location":"gait/#left-foot-gait-events","title":"Left foot gait events","text":""},{"location":"gait/#right-foot-gait-events","title":"Right foot gait events","text":""},{"location":"gait/#comparing-trajectories-across-systems","title":"Comparing trajectories across systems","text":""},{"location":"gait/#normalized-trajectories","title":"Normalized Trajectories","text":"<p>We can now look at the normalized trajectories for various markers across the gait cycle. Below is the average hip, knee, ankle, and foot markers for both MediaPipe and Qualisys for a representative participant for the .5m/s walking speed. Shaded error bars represent one standard deviation from the mean. </p> <p> </p>"},{"location":"gait/#trajectory-error-across-speeds","title":"Trajectory error across speeds","text":"<p>Below you can flip between treadmill speeds. Each panel shows FreeMoCap \u2212 Qualisys trajectory error (mean \u00b1 SD) over the gait cycle.</p> 0.5 m/s1.0 m/s1.5 m/s2.0 m/s2.5 m/s <p></p> <p><p>      Open interactive version \u2197    </p></p> <p></p> <p><p>      Open interactive version \u2197    </p></p> <p></p> <p><p>      Open interactive version \u2197    </p></p> <p></p> <p><p>      Open interactive version \u2197    </p></p> <p></p> <p><p>      Open interactive version \u2197    </p></p>"},{"location":"gait/#rmse-per-joint-trajectory","title":"RMSE Per Joint Trajectory","text":"<p>We can also look at the RMSE per joint trajectory across speeds. </p> <p> </p> <p>And we can break down the RMSE data by participant data as well.</p>"},{"location":"gait/#comparing-joint-angles-across-systems","title":"Comparing joint angles across systems","text":""},{"location":"gait/#normalized-joint-angles","title":"Normalized Joint Angles","text":"<p>For the same participant and speed as above, we can also look at the joint angles for the hip, knee, and ankle across the gait cycle. Shaded error bars represent one standard deviation from the mean.</p> <p> </p>"},{"location":"gait/#mean-joint-angles-across-speeds","title":"Mean joint angles across speeds","text":"<p>Below you can flip between treadmill speeds. Each tab shows the mean \u00b1 SD joint angles (participant-balanced) for that condition.</p> 0.5 m/s1.0 m/s1.5 m/s2.0 m/s2.5 m/s <p></p> <p><p>      Open interactive version \u2197    </p></p> <p></p> <p><p>      Open interactive version \u2197    </p></p> <p></p> <p><p>      Open interactive version \u2197    </p></p> <p></p> <p><p>      Open interactive version \u2197    </p></p> <p></p> <p><p>      Open interactive version \u2197    </p></p>"},{"location":"prosthetic_tracking/","title":"Prosthetic Tracking","text":""},{"location":"prosthetic_tracking/#overview","title":"Overview","text":"<p>Prosthetic alignment and fit is important to the overall health, satisfaction, and comfort of a prosthesis user. Most often, prosthetic alignment in-clinic is guided by clinician visual assessment, which may not be sensitive to to small changes in gait due to alignment. Other more sensitive tools, such as marker-based motion capture systems, may be out of scope cost and resource-wise for in-clinic use. </p> <p>Markerless motion capture represents a flexible way for clinicians to see the impact of prosthetic alignment in-clinic. One barrier to use for this purpose however, is that typical pose estimation software is trained on non-prosthetic limbs and poorly track prosthetic limbs as a result. Many markerless motion capture systems rely on a particular pose estimation software - which limits what might be suitable for this use case. Options such as DeepLabCut do provide users with ways of custom training their own pose estimation model - but requires heavy technical knowledge to operate, and still requires knowledge of 3d reconstruction and triangulation. </p> <p>FreeMoCap was designed with a modular architecture in mind - with the goal to create a framework that could allow for the use of different pose estimation software, depending on research needs. This validation utilizes a custom-made DeepLabCut wrapper to train a DLC pose estimation model on a prosthetic limb and integrates it into the FreeMoCap pipeline to look at kinematic shifts due to adjustments in alignment. </p>"},{"location":"prosthetic_tracking/#methods","title":"Methods","text":""},{"location":"prosthetic_tracking/#study-design","title":"Study Design","text":"<p>We examined one subject with a trans-femoral amputation. The subject was asked to walk for trials of one minute in length on a treadmill at a self-selected comfortable walking speed. For each trial, the subjects prosthetic alignment was adjusted in one of 3 categories, with 5 levels of adjustment from each. </p> <p>1) Changing the leg length of the prosthetic by +-.5/1.5 in. increments from its neutral length  2) Changing the ankle plantarflexion/dorsiflexion angle by +- 2.6/5.8 degrees from its neutral angle  3) Changing the toe in/out angle by +-3/6 degrees from its neutral angle. </p>"},{"location":"prosthetic_tracking/#data-collection","title":"Data Collection","text":"<p>For each trial, the subject was recorded using Qualisys, a marker-based motion capture system, and six webcams recording synchronous video through FreeMoCap software.</p>"},{"location":"prosthetic_tracking/#data-analysis","title":"Data Analysis","text":""},{"location":"prosthetic_tracking/#motion-capture-processing","title":"Motion Capture Processing","text":"<p>Qualisys data was processed and cleaned in QTM and exported as a TSV file. Two of the six videos were removed from final reconstruction due to heavy occlusion of the prosthetic limb. The remaining synchronized webcam videos were run through the standardFreeMoCap pipeline - providing 3D data using MediaPipe pose estimation software. </p>"},{"location":"prosthetic_tracking/#dlc-training","title":"DLC Training","text":"<p>Using a custom-made wrapper of DeepLabCut - we trained a model to track the knee, ankle, heel, and toe locations on the prosthetic. Only frames from the neutral stance videos were used in training the model. The model was run on the synchronized videos, producing 2D DeepLabCut keypoints for the prosthetic.</p> <p>The 2D DLC keypoints for each video were then run through the FreeMoCap 3D reconstruction pipeline - producing 3D data for the prosthetic. This data was then spliced into the existing MediaPipe 3D data, replacing the 3D prosthetic leg data calculated by MediaPipe.</p> <p></p>"},{"location":"prosthetic_tracking/#data-pre-processing","title":"Data Pre-Processing","text":"<p>Qualisys joint centers were calculated from the exported TSV marker data. Qualisys and FreeMoCap joint center data were interpolated and then filtered using a low-pass 4th order Butterworth filter with a 7Hz cutoff frequency. The Qualisys data was temporally aligned and downsampled to match timestamps with the FreeMoCap data. FreeMoCap data was then spatially aligned with Qualisys into the lab coordinate system (X mediolateral, Y anterior-posterior, Z height)</p>"},{"location":"prosthetic_tracking/#results","title":"Results","text":""},{"location":"prosthetic_tracking/#leg-length-adjustments","title":"Leg length adjustments","text":"<p>Leg length was calculated as the average knee-ankle joint center length over a given trial per system using:</p> <p>\ud835\udc59\ud835\udc52\ud835\udc54 \ud835\udc59\ud835\udc52\ud835\udc5b\ud835\udc54\ud835\udc61\u210e= \u221a((\ud835\udc65_1\u2212\ud835\udc65_2 )^2+(\ud835\udc66_1\u2212\ud835\udc66_2 )^2+(\ud835\udc67_1\u2212\ud835\udc67_2 )^2 )  x_1, y_1, z_1 = 3D coordinates of the ankle  x_2, y_2, z_2 = 3D coordinates of the knee </p> <p>Below is the comparison of measured changes in leg length vs. our expected value.  </p>"},{"location":"prosthetic_tracking/#ankle-dorsiplantar-flexion-adjustments","title":"Ankle dorsi/plantar flexion adjustments","text":"<p>Defined segment coordinate systems and computed relative rotation between distal/proximal segments. The relative orientation was decomposed in Z-X-Y Cardan angles. Angles were normalized using a neutral stance period. Gait events were detected using velocity zero-crossings from Qualisys data (heel strike as positive to negative, toe off as negative to positive) (Zeni, 2008) for both systems. Joint angles were then normalized by gait cycle. </p> <p>The ankle dorsi/plantarflexion angles across adjustments are visualized below for FreeMoCap on the left and Qualisys on the right. </p> <p> </p>"},{"location":"prosthetic_tracking/#toe-intoe-out-adjustments","title":"Toe-in/Toe-out Adjustments","text":"<p>To track adjustments to the toe-in/toe-out of the prosthetic foot, we calculated the foot progression angle (FPA) using:</p> <p>\ud835\udc39\ud835\udc43\ud835\udc34=\ud835\udc4e\ud835\udc5f\ud835\udc50\ud835\udc61\ud835\udc4e\ud835\udc5b2((\ud835\udc4e\ud835\udc65\ud835\udc4f)\u2219\ud835\udc5f, \ud835\udc4e\u2219\ud835\udc4f)  a = long axis of the foot (vector from heel to toe)  b = direction of walking = [0, 1, 0]  r = unit normal to plane = [0, 0, 1] </p> <p> </p>"}]}